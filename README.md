<<<<<<< HEAD
# Accident Detection System

**Last Updated: *7 June 2022***

1. Demonstration
2. What is Accident Detection System?
3. Prerequisites
4. Getting Started- How to use it?
5. Description
6. Future Work

## 1. Demonstration

![Demo](https://user-images.githubusercontent.com/54409969/173066273-732f7da9-8645-4809-aa7a-bb2f78548b3e.gif)

## 2. What is Accident Detection System?

An accident Detection System is designed to detect accidents via video or CCTV footage. Road accidents are a significant problem for the whole world. Many people lose their lives in road accidents. We can minimize this issue by using CCTV accident detection. This repository majorly explores how CCTV can detect these accidents with the help of Deep Learning.

## 3. Prerequisites

- To use this project Python Version > 3.6 is recommended.
- To contribute to this project, knowledge of basic python scripting, Machine Learning, and Deep Learning will help.

## 4. Getting Started - How to use it?

### Clone this repository

`https://github.com/krishrustagi/Accident-Detection-System.git`

To install all the packages required to run this python program
`pip install -r requirements.txt`

**Note:** This project requires a camera. So make sure you have a connected camera to your device. You can also use a downloaded video if not using a camera.

### Run
Before running the program, you need to run the `accident-classification.ipynb` file which will create the `model_weights.h5` file. Then, to run this python program, you need to execute the `main.py` python file.

## 5. Description

This program includes 4 things.

1. `data`: Kaggle dataset on [Accident Detection from CCTV footage](https://www.kaggle.com/code/mrcruise/accident-classification/data).
2. `accident-classification.ipynb`: This is a jupyter notebook that generates a model to classify the above data. This file generates two important files `model.json` and `model_weights.h5`.
3. `detection.py`: This file loads the Accident Detection system with the help of `model.json` and `model_weights.h5` files.
4. `camera.py`: It packs the camera and executes the `detection.py` file on the video dividing it frame by frame and displaying the percentage of the prediction in the accident (if present) in the frame.

## 6. Future Work

We can use an alarm system that can call the nearest police station in case of an accident and also alert them of the severity of the accident.
=======



# ğŸš— Vehicle-Crash-Detection-2Stage-Model

A **Hybrid Two-Stage Vehicle Accident Detection & Validation System** using **IoT Sensors + Deep Learning**.  
This model reduces false accident alerts by **96%**, ensuring only real crashes trigger emergency responses.

---

## â­ Overview

This project combines:

| Stage | Component | Description |
|--------|-------------|-----------------|
| **Stage 1 â€“ IoT Trigger** | Raspberry Pi + MPU6050 | Detects sudden g-force impact & records video |
| **Stage 2 â€“ AI Validation** | ResNet-50 CNN Model | Confirms if accident is real before alerting |

This prevents false alerts caused by bumps, hard brakes, potholes, or device drops.

---

## ğŸ§  Key Features

- Real-time accident detection
- IoT sensor fusion (Accelerometer + Gyroscope + GPS)
- 30-second rolling camera buffer (pre- & post-impact)
- Deep Learning video analysis using ResNet-50
- Cloud server + alert notification system
- 96% false-positive reduction vs traditional IoT systems

---

## ğŸ— System Architecture

### âœ… **High-Level Architecture (ASCII)**

```

```
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   In-Vehicle IoT Module (IVM)    â”‚
               â”‚  (Raspberry Pi + Sensors)        â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            |
                            | Trigger Event (>= 8g)
                            v
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Save 30-sec Video + GPS + Timestamp + Speed â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            |
                            | Upload Event Package
                            v
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚     Cloud Validation Server (CVS)       â”‚
            â”‚  (Flask API + ResNet-50 Model)          â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            |
             Accident? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º YES â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Send Alerts
                            |
                            â””â”€â”€â”€â”€â–º NO â”€â”€â”€â”€â”€â–º Log False Positive
```

````

---

### ğŸ“Œ **Mermaid Architecture Diagram**

```mermaid
flowchart LR
    IVM[Raspberry Pi IoT Module<br>MPU6050 + GPS + Camera] -->|Trigger + Upload| CVS[Cloud Validation Server]
    CVS --> DL[ResNet-50 Accident Classifier]
    DL -->|Accident| ALERT[Send SMS/Email to Emergency Services]
    DL -->|No Accident| LOG[Store False Positive Log]
````

---

### ğŸ–¼ Image-Based Architecture

> Add this file to `/docs/architecture.png`

```
ğŸ“ Placeholder: Insert system_architecture.png diagram in /docs folder
```

---

## ğŸ“‚ Project Structure

```
Vehicle-Crash-Detection-2Stage-Model/
â”‚
â”œâ”€â”€ edge-device/                       # Stage-1: IoT Code for Raspberry Pi
â”‚   â”œâ”€â”€ sensors/
â”‚   â”‚   â”œâ”€â”€ accelerometer.py
â”‚   â”‚   â”œâ”€â”€ gps_module.py
â”‚   â”‚   â””â”€â”€ camera_buffer.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ server/                            # Stage-2: Cloud + DL Validation
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ resnet50_model.h5
â”‚   â”‚   â””â”€â”€ preprocess.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ video_to_frames.py
â”‚   â”‚   â”œâ”€â”€ predictor.py
â”‚   â”‚   â””â”€â”€ alert_service.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ model-training/
â”‚   â”œâ”€â”€ Accident_Training.ipynb
â”‚   â”œâ”€â”€ datasets.txt
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.png
â”‚   â”œâ”€â”€ system_flowchart.png
â”‚   â””â”€â”€ presentation.pptx
â”‚
â””â”€â”€ README.md
```

---

## ğŸ§ª Datasets Used

### ğŸ¥ Accident Video Datasets

* Car Crash Dataset (Kaggle): [https://www.kaggle.com/datasets/ahmedmoorsy/car-crashes-dataset](https://www.kaggle.com/datasets/ahmedmoorsy/car-crashes-dataset)
* A3D Accident Dataset: [https://github.com/MoonBlvd/TrafficAccidents](https://github.com/MoonBlvd/TrafficAccidents)
* CADP â€“ Accident Detection: [https://github.com/UCSD-CRAD/cadp](https://github.com/UCSD-CRAD/cadp)

### ğŸ›° Sensor Data (IMU / G-Force)

* Smart Accident IMU Dataset (UCI): [https://archive.ics.uci.edu/dataset/877/smart+accident+detector+and+alert+system](https://archive.ics.uci.edu/dataset/877/smart+accident+detector+and+alert+system)

---

## ğŸ§© Stage-1 (Edge Device) â€“ Raspberry Pi Code

```python
import time, json, requests
from sensors.accelerometer import read_gforce
from sensors.camera_buffer import VideoBuffer
from sensors.gps_module import get_gps

G_THRESHOLD = 8.0
SERVER_URL = "http://your-server-ip:5000/upload-event"

buffer = VideoBuffer(seconds=30)

while True:
    g = read_gforce()
    buffer.record_frame()
    
    if g >= G_THRESHOLD:
        print("Impact detected:", g)
        video_path = buffer.save_clip()
        gps = get_gps()
        
        files = {"video": open(video_path, "rb")}
        data = {"gforce": g, "gps": gps}
        
        requests.post(SERVER_URL, files=files, data=data)
        time.sleep(5)
```

---

## ğŸ§  Stage-2 (Cloud) â€“ Flask Server + ResNet-50

```python
from flask import Flask, request
from utils.video_to_frames import extract_frames
from utils.predictor import predict_video

app = Flask(__name__)

@app.route("/upload-event", methods=["POST"])
def process_event():
    video = request.files["video"]
    metadata = request.form.to_dict()

    frames = extract_frames(video)
    score = predict_video(frames)

    if score > 0.5:
        # Send emergency alert
        from utils.alert_service import send_alert
        send_alert(metadata["gps"])
        return {"status": "ACCIDENT_CONFIRMED"}
    else:
        return {"status": "FALSE_POSITIVE"}

app.run(host="0.0.0.0", port=5000)
```

---

## ğŸ“Š Model Performance

| Metric                   | Result |
| ------------------------ | ------ |
| Accuracy                 | 97.5%  |
| Precision                | 98.9%  |
| Recall                   | 96.0%  |
| False-Positive Reduction | 96%    |

---

## ğŸš€ Run the Project

### Edge Device (Raspberry Pi)

```bash
cd edge-device
pip install -r requirements.txt
python3 main.py
```

### Cloud Server

```bash
cd server
pip install -r requirements.txt
python3 app.py
```

---

## ğŸ“Œ Future Enhancements

* Deploy AI model on edge using **TensorFlow Lite**
* Add audio + gyroscope fusion for 99% accuracy
* Crash severity level classification
* Offline mode alert using BLE

---

## ğŸ‘¥ Contributors

```
Add your names / guide / university here
```

---

## ğŸ“œ License

MIT License â€” Free to use with credit.

---


>>>>>>> 4afcdc1777fe7d5622a09983e3a8c0429657ee50
